import requests
import pandas as pd
import yfinance as yf
import json
import os
import re
from datetime import datetime, date, timedelta

# --- è¨­å®šå€ ---
TG_TOKEN = os.environ.get("TG_TOKEN")
TG_CHAT_ID = os.environ.get("TG_CHAT_ID")

HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Accept': 'application/json, text/javascript, */*; q=0.01',
}

# --- é—œéµä¿®æ­£ï¼šå–å¾—å°ç£æ™‚é–“ ---
def get_tw_now():
    # GitHub ä¸»æ©Ÿæ˜¯ UTCï¼Œå°ç£æ˜¯ UTC+8
    return datetime.utcnow() + timedelta(hours=8)

def send_tg(message):
    if not TG_TOKEN or not TG_CHAT_ID: return
    try:
        url = f"https://api.telegram.org/bot{TG_TOKEN}/sendMessage"
        requests.post(url, json={"chat_id": TG_CHAT_ID, "text": message, "parse_mode": "Markdown"})
    except: pass

def get_price(code, market):
    if not code or not str(code).isdigit() or len(str(code)) != 4:
        return "N/A", "N/A"
    suffix = ".TW" if market == "ä¸Šå¸‚" else ".TWO"
    try:
        ticker = yf.Ticker(f"{code}{suffix}")
        hist = ticker.history(period="1d", timeout=5)
        if hist.empty: return "N/A", "N/A"
        
        close = round(hist['Close'].iloc[-1], 2)
        prev = ticker.info.get('previousClose', None)
        if prev is None and len(hist['Open']) > 0: prev = hist['Open'].iloc[0]
        
        if prev:
            change = round(((close - prev) / prev) * 100, 2)
            return close, change
        return close, "N/A"
    except: return "N/A", "N/A"

def clean_str(s):
    if s is None: return ""
    return str(s).replace('ï½', '~').replace(' ', '').strip()

def roc_to_ad_str(roc_date_str):
    """å°‡ 115/01/20 è½‰ç‚º 2026-01-20"""
    try:
        parts = re.split(r'[-/]', roc_date_str)
        if len(parts) == 3:
            y = int(parts[0]) + 1911
            return f"{y}-{parts[1]}-{parts[2]}"
    except: pass
    return get_tw_now().strftime("%Y-%m-%d")

def extract_dates_from_row(row_dict):
    """
    ä¸æŒ‡å®šæ¬„ä½ï¼Œç›´æ¥æƒææ•´ç­†è³‡æ–™çš„æ‰€æœ‰ Valuesï¼Œæ‰¾å‡ºæ—¥æœŸ
    å›å‚³: (å€’æ•¸å¤©æ•¸, çµæŸæ—¥æœŸ, å®Œæ•´å€é–“)
    """
    try:
        full_text = " ".join([str(v) for v in row_dict.values()])
        full_text = clean_str(full_text)
        
        matches = re.findall(r'(\d{3})[-/](\d{2})[-/](\d{2})', full_text)
        if not matches:
            matches = re.findall(r'(\d{3})(\d{2})(\d{2})', full_text)

        if len(matches) >= 2:
            y_end, m_end, d_end = matches[-1]
            y_start, m_start, d_start = matches[-2]
            
            y = int(y_end)
            y = y + 1911 if y < 1911 else y
            target = date(y, int(m_end), int(d_end))
            
            # ã€é—œéµä¿®æ­£ã€‘é€™è£¡ä¹Ÿè¦ç”¨å°ç£æ™‚é–“çš„ã€Œä»Šå¤©ã€ä¾†è¨ˆç®—å€’æ•¸
            tw_today = get_tw_now().date()
            diff = (target - tw_today).days
            
            end_date_str = f"{y_end}/{m_end}/{d_end}"
            full_period = f"{y_start}/{m_start}/{d_start}~{end_date_str}"
            
            return diff, end_date_str, full_period
    except: pass
    return 0, "", ""

def scrape_current():
    data = []
    
    # --- 1. ä¸Šå¸‚ (TWSE) ---
    print("æ­£åœ¨æŠ“å–ä¸Šå¸‚è³‡æ–™...")
    try:
        res = requests.get("https://www.twse.com.tw/rwd/zh/announcement/punish?response=json", headers=HEADERS, timeout=15)
        js = res.json()
        if js['stat'] == 'OK':
            print(f"ä¸Šå¸‚æŠ“åˆ° {len(js['data'])} ç­†")
            for r in js['data']:
                try:
                    raw_pub_date = str(r[1]).strip()
                    raw_code = str(r[2]).strip()
                    raw_name = str(r[3]).strip()
                    raw_period = str(r[6]).strip()
                    raw_measure = str(r[7]).strip()
                    raw_detail = str(r[8]).strip()

                    if not (raw_code.isdigit() and len(raw_code) == 4): continue

                    level = "5åˆ†ç›¤"
                    if "ç¬¬äºŒæ¬¡" in raw_measure: level = "20åˆ†ç›¤"
                    elif "20åˆ†é˜" in raw_detail or "äºŒååˆ†é˜" in raw_detail: level = "20åˆ†ç›¤"
                    elif "45åˆ†é˜" in raw_detail or "å››åäº”åˆ†é˜" in raw_detail: level = "45åˆ†ç›¤"
                    elif "60åˆ†é˜" in raw_detail: level = "60åˆ†ç›¤"

                    countdown, pure_end_date, _ = extract_dates_from_row({'p': raw_period})
                    if not pure_end_date: pure_end_date = raw_period

                    data.append({
                        "market": "ä¸Šå¸‚",
                        "code": raw_code,
                        "name": raw_name,
                        "publish_date": raw_pub_date,
                        "period": raw_period,
                        "reason": raw_measure,
                        "level": level,
                        "end_date": pure_end_date,
                        "countdown": countdown
                    })
                except: continue
    except Exception as e: print(f"ä¸Šå¸‚éŒ¯èª¤: {e}")

    # --- 2. ä¸Šæ«ƒ (TPEx) ---
    print("æ­£åœ¨æŠ“å–ä¸Šæ«ƒè³‡æ–™ (OpenAPI)...")
    try:
        url = "https://www.tpex.org.tw/openapi/v1/tpex_disposal_information"
        res = requests.get(url, headers=HEADERS, timeout=15)
        rows = res.json()
        
        print(f"ä¸Šæ«ƒ OpenAPI é€£ç·šæˆåŠŸï¼å…± {len(rows)} ç­† raw data")
        
        for r in rows:
            try:
                raw_code = str(r.get('SecuritiesCompanyCode', r.get('è­‰åˆ¸ä»£è™Ÿ', ''))).strip()
                raw_name = str(r.get('CompanyName', r.get('è­‰åˆ¸åç¨±', ''))).strip()
                
                if not raw_code:
                    for v in r.values():
                        if str(v).isdigit() and len(str(v)) == 4:
                            raw_code = str(v)
                            break

                if not (raw_code.isdigit() and len(raw_code) == 4): continue

                countdown, pure_end_date, full_period = extract_dates_from_row(r)
                
                level = "5åˆ†ç›¤"
                full_text = str(r)
                if "20åˆ†é˜" in full_text or "äºŒååˆ†é˜" in full_text: level = "20åˆ†ç›¤"
                elif "45åˆ†é˜" in full_text or "å››åäº”åˆ†é˜" in full_text: level = "45åˆ†ç›¤"
                elif "60åˆ†é˜" in full_text: level = "60åˆ†ç›¤"
                elif "ç¬¬äºŒæ¬¡" in full_text: level = "20åˆ†ç›¤"

                data.append({
                    "market": "ä¸Šæ«ƒ",
                    "code": raw_code,
                    "name": raw_name if raw_name else "æœªçŸ¥",
                    "publish_date": "", 
                    "period": full_period if full_period else "æ—¥æœŸæœªæŠ“å–",
                    "reason": "", 
                    "level": level,
                    "end_date": pure_end_date if pure_end_date else "æ—¥æœŸæœªæŠ“å–",
                    "countdown": countdown
                })
            except Exception as ex: continue
            
    except Exception as e: print(f"ä¸Šæ«ƒéŒ¯èª¤: {e}")

    return data

def main():
    print("=== ç¨‹å¼é–‹å§‹åŸ·è¡Œ ===")
    
    # å–å¾—å°ç£æ™‚é–“ç‰©ä»¶
    tw_now = get_tw_now()
    tw_today_str = tw_now.strftime("%Y-%m-%d")
    
    old_data = {"disposal_stocks": [], "exited_stocks": []}
    if os.path.exists('data.json'):
        try:
            with open('data.json', 'r', encoding='utf-8') as f:
                old_data = json.load(f)
        except: pass
    
    raw_new = scrape_current()
    
    if len(raw_new) == 0 and len(old_data.get('disposal_stocks', [])) > 0:
        print("âš ï¸ è­¦å‘Šï¼šæœ¬æ¬¡æœªæŠ“åˆ°æœ‰æ•ˆè³‡æ–™ï¼Œæš«æ™‚ä½¿ç”¨èˆŠè³‡æ–™")
        raw_new = old_data['disposal_stocks']
        for s in raw_new:
            try:
                 diff, _, _ = extract_dates_from_row({'period': s['period']})
                 s['countdown'] = diff
            except: pass

    new_processed = [] 
    recently_exited = [] 
    new_codes = set()
    
    old_exited = old_data.get('exited_stocks', [])

    for s in raw_new:
        code = s['code']
        price, change = get_price(code, s['market'])
        s['price'] = price
        s['change'] = change

        if s['countdown'] >= 0:
            if code not in new_codes:
                new_processed.append(s)
                new_codes.add(code)
        else:
            print(f"ç™¼ç¾éæœŸè‚¡ç¥¨: {s['name']} ({s['code']})ï¼Œç§»è‡³å·²å‡ºé—œ")
            exit_date = roc_to_ad_str(s['end_date'])
            s['exit_date'] = exit_date
            
            if not any(ex['code'] == code for ex in recently_exited):
                recently_exited.append(s)

    new_processed.sort(key=lambda x: x['countdown'])

    valid_old_stocks = [s for s in old_data.get('disposal_stocks', []) 
                        if str(s['code']).isdigit() and len(str(s['code'])) == 4]
    
    if len(raw_new) > 0:
        for old_s in valid_old_stocks:
            if old_s['code'] not in new_codes and old_s['code'] not in [x['code'] for x in recently_exited]:
                p, c = get_price(old_s['code'], old_s['market'])
                old_s.update({"price": p, "change": c, "exit_date": tw_today_str})
                recently_exited.append(old_s)

    for ex in old_exited:
        try:
            if not (str(ex['code']).isdigit() and len(str(ex['code'])) == 4): continue
            if ex['code'] in new_codes: continue
            if ex['code'] in [x['code'] for x in recently_exited]: continue

            # ä½¿ç”¨å°ç£æ™‚é–“è¨ˆç®—å¤©æ•¸å·®
            days_diff = (tw_now - datetime.strptime(ex['exit_date'], "%Y-%m-%d")).days
            if days_diff <= 5: 
                recently_exited.append(ex)
        except: pass

    tg_msg_list = []
    old_codes_set = {s['code'] for s in valid_old_stocks}
    for s in new_processed:
        if s['code'] not in old_codes_set and len(old_codes_set) > 0:
            tg_msg_list.append(s)

    etf_data = [
        {"code":"00940","name":"å…ƒå¤§è‡ºç£åƒ¹å€¼é«˜æ¯","action":"æ–°å¢","stock":"é•·æ¦®èˆª(2618)","date":"2026-05-17"},
        {"code":"00878","name":"åœ‹æ³°æ°¸çºŒé«˜è‚¡æ¯","action":"åˆªé™¤","stock":"è‹±æ¥­é”(2356)","date":"2026-05-20"}
    ]

    if tg_msg_list:
        msg_lines = ["ğŸš¨ **å°è‚¡è™•ç½®æ–°å¢**"]
        for x in tg_msg_list:
            msg_lines.append(f"{x['name']}({x['code']})\n{x['level']}")
        send_tg("\n\n".join(msg_lines))

    final_output = {
        # ã€é—œéµã€‘é€™è£¡å¯«å…¥çš„ update_time ç¾åœ¨æ˜¯å°ç£æ™‚é–“äº†
        "update_time": tw_now.strftime("%Y-%m-%d %H:%M:%S"),
        "disposal_stocks": new_processed,
        "exited_stocks": recently_exited,
        "etf_stocks": etf_data
    }
    
    with open('data.json', 'w', encoding='utf-8') as f:
        json.dump(final_output, f, ensure_ascii=False, indent=4)
        
    print(f"=== åŸ·è¡ŒçµæŸï¼ŒæˆåŠŸè™•ç† {len(new_processed)} ç­†è³‡æ–™ ===")
    print(f"=== å·²å‡ºé—œè³‡æ–™å…± {len(recently_exited)} ç­† ===")

if __name__ == "__main__":
    main()
